import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from "@google/generative-ai";
import { UserProfile } from '@/types';

const genAI = process.env.GOOGLE_API_KEY && process.env.GOOGLE_API_KEY !== "your-google-api-key-here"
  ? new GoogleGenerativeAI(process.env.GOOGLE_API_KEY)
  : null;

// Tipos de ocasi√£o para detec√ß√£o autom√°tica
const occasionTypes = ['trabalho', 'encontro', 'passeio', 'festa', 'evento', 'esporte', 'viagem', 'casa'];
const styleTypes = ['casual', 'formal', 'elegante', 'descontra√≠do', 'moderno', 'cl√°ssico'];

// Gera mensagem inicial personalizada
function generateInitialMessage(): string {
  return `Ol√°! üëã Sou sua assistente de moda pessoal! \n\nEstou aqui para te ajudar a criar o look perfeito para qualquer ocasi√£o. ‚ú®\n\nVamos come√ßar! Me conta sobre a ocasi√£o de hoje?`;
}

// Detectar ocasi√£o e estilo na mensagem
function extractInfoFromMessage(message: string): Partial<UserProfile> {
  const lower = message.toLowerCase();
  const updates: Partial<UserProfile> = {};

  // Detectar ocasi√£o
  occasionTypes.forEach(occasion => {
    if (lower.includes(occasion)) {
      updates.ocasiao = occasion;
    }
  });

  // Detectar estilo
  styleTypes.forEach(style => {
    if (lower.includes(style)) {
      updates.estiloDesejado = style;
    }
  });

  // Detectar restri√ß√µes
  if (lower.includes('n√£o quero') || lower.includes('n√£o gosto')) {
    const restrictionPart = lower.split(/n√£o quero|n√£o gosto/)[1];
    if (restrictionPart) {
      updates.restricoes = restrictionPart.trim();
    }
  }
  
  return updates;
}

// Fun√ß√£o de fallback quando API do Gemini falha
function generateFallbackResponse(
  message: string,
  userProfile: {
    occasion?: string;
    weather?: string;
    style?: string;
  },
  conversationHistory: Array<{ isUser: boolean; text: string }>
) {
  const lowerMessage = message.toLowerCase();
  
  // Se √© uma sauda√ß√£o inicial (apenas no in√≠cio da conversa)
  if (conversationHistory.length === 0) {
    return `Ol√°! Sou sua assistente de moda pessoal! üëó‚ú®\n\nPara criar o look perfeito para voc√™, me conte: para que ocasi√£o voc√™ precisa se vestir hoje?\n\nüìç **Ocasi√µes que posso ajudar:**\n‚Ä¢ Trabalho/reuni√£o\n‚Ä¢ Encontro rom√¢ntico\n‚Ä¢ Passeio casual\n‚Ä¢ Festa/evento\n‚Ä¢ Exerc√≠cios\n‚Ä¢ Viagem\n‚Ä¢ Ficar em casa`;
  }
  
  // Se o usu√°rio est√° cumprimentando no meio da conversa
  if (lowerMessage.includes('oi') || lowerMessage.includes('ol√°')) {
    return `Oi! Como posso ajudar voc√™ com seu look hoje? üòä\n\nMe conte para que ocasi√£o voc√™ precisa se vestir!`;
  }
  
  // Se mencionou ocasi√£o
  if (lowerMessage.includes('trabalho') || lowerMessage.includes('reuni√£o')) {
    return `Perfeito! Para o trabalho, vou criar um look profissional e elegante para voc√™! üíº\n\nMe conte mais alguns detalhes:\n‚Ä¢ Qual √© o clima hoje?\n‚Ä¢ Voc√™ prefere algo mais formal ou business casual?\n‚Ä¢ Tem alguma cor favorita ou que deve evitar?`;
  }
  
  if (lowerMessage.includes('encontro') || lowerMessage.includes('rom√¢ntico')) {
    return `Que rom√¢ntico! üíï Vou criar um look encantador para seu encontro!\n\nPara personalizar melhor:\n‚Ä¢ Onde ser√° o encontro? (restaurante, cinema, parque...)\n‚Ä¢ Qual seu estilo preferido? (elegante, casual, boho...)\n‚Ä¢ Tem alguma pe√ßa favorita no guarda-roupa?`;
  }
  
  if (lowerMessage.includes('festa') || lowerMessage.includes('evento')) {
    return `Festa! üéâ Vamos criar um look incr√≠vel para voc√™ arrasar!\n\nMe ajude com os detalhes:\n‚Ä¢ Que tipo de festa? (anivers√°rio, casamento, balada...)\n‚Ä¢ √â durante o dia ou √† noite?\n‚Ä¢ Tem dress code espec√≠fico?`;
  }
  
  // Se tem informa√ß√µes suficientes, gera sugest√£o completa
  if (userProfile.occasion && (userProfile.weather || userProfile.style)) {
    return generateCompleteLookSuggestion(userProfile);
  }
  
  // Resposta gen√©rica para continuar a conversa
  return `Entendi! Para criar o look ideal, preciso saber mais alguns detalhes:\n\n‚Ä¢ Para que ocasi√£o voc√™ precisa se vestir?\n‚Ä¢ Como est√° o clima hoje?\n‚Ä¢ Qual seu estilo preferido?\n\nCom essas informa√ß√µes, posso sugerir looks incr√≠veis para voc√™! ‚ú®`;
}

// Fun√ß√£o para gerar sugest√£o completa de look
function generateCompleteLookSuggestion(userProfile: {
  occasion?: string;
  weather?: string;
}) {
  const occasion = userProfile.occasion || 'casual';
  const weather = userProfile.weather || 'ameno';
  
  return `## üëó **Look Principal**\n\n**Para ${occasion}:**\n‚Ä¢ **Top:** Blusa social branca ou camisa de seda\n‚Ä¢ **Bottom:** Cal√ßa alfaiataria ou saia midi\n‚Ä¢ **Cal√ßado:** Sapato fechado confort√°vel ou scarpin baixo\n‚Ä¢ **Terceira pe√ßa:** Blazer estruturado\n\n---\n\n## ‚ú® **Alternativas**\n\n**Op√ß√£o 2:** Vestido midi + cardigan + sapatilha\n**Op√ß√£o 3:** Cal√ßa jeans escura + blusa elegante + jaqueta\n\n---\n\n## üëú **Acess√≥rios**\n‚Ä¢ Bolsa estruturada pequena/m√©dia\n‚Ä¢ Rel√≥gio delicado\n‚Ä¢ Brincos discretos\n‚Ä¢ Cinto fino (opcional)\n\n---\n\n## üí° **Dica Especial**\n\nPara ${weather}, lembre-se de levar uma pe√ßa extra para se adaptar √† temperatura! A confian√ßa √© o melhor acess√≥rio - use o que faz voc√™ se sentir bem! ‚ú®\n\n*Precisa de mais alguma coisa? Posso ajudar com outras ocasi√µes!*`;
}

// Fun√ß√£o principal que chama a IA para processar a conversa
async function callGeminiForChat(
  message: string,
  profile: Partial<UserProfile>,
  conversationHistory: Array<{ isUser: boolean; text: string }>
): Promise<string> {
  if (!genAI) return "Desculpe, n√£o consegui processar sua mensagem agora. Tente novamente mais tarde.";
  
  try {
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    // Hist√≥rico da conversa para contexto
    const historyContext = conversationHistory.map(msg => 
      `${msg.isUser ? 'Usu√°rio' : 'Assistente'}: ${msg.text}`
    ).join('\n');
    
    const prompt = `Voc√™ √© uma assistente de moda pessoal especializada em criar looks personalizados. Seu objetivo √©:

1. **CUMPRIMENTO E IDENTIFICA√á√ÉO DA OCASI√ÉO:**
   - APENAS cumprimente se for a primeira mensagem da conversa ou se o usu√°rio estiver cumprimentando
   - Identifique a ocasi√£o (trabalho, encontro, passeio, festa/evento, esporte, viagem, casa)
   - Se a ocasi√£o n√£o estiver clara, fa√ßa perguntas espec√≠ficas

2. **CLASSIFICA√á√ÉO E DETALHAMENTO:**
   - Classifique a ocasi√£o em categorias (formal/casual, interno/externo, etc.)
   - Colete informa√ß√µes sobre: local espec√≠fico, hor√°rio, clima, prefer√™ncias, restri√ß√µes

3. **ESTRUTURA DE RESPOSTA (quando tiver informa√ß√µes suficientes):**
   - **Look Principal:** Descri√ß√£o detalhada da sugest√£o principal
   - **Alternativa 1:** Segunda op√ß√£o com justificativa
   - **Alternativa 2:** Terceira op√ß√£o diferenciada
   - **Acess√≥rios:** Sugest√µes de complementos
   - **Dica Extra:** Conselho personalizado

4. **PERSONALIZA√á√ÉO:**
   - Use o clima atual: ${profile.weatherData?.temperature || 'N/A'}¬∞C, ${profile.weatherData?.condition || 'N/A'}
   - Considere a localiza√ß√£o: ${profile.cidade || 'N/A'}
   - Adapte ao perfil: ocasi√£o=${profile.ocasiao || 'N/A'}, estilo=${profile.estiloDesejado || 'N/A'}

5. **TRATAMENTO DE ERROS:**
   - Para respostas vagas: fa√ßa perguntas direcionadas
   - Para contexto fora de moda: redirecione gentilmente
   - Mantenha sempre o foco em moda e estilo

**HIST√ìRICO DA CONVERSA:**
${historyContext}

**MENSAGEM ATUAL DO USU√ÅRIO:** ${message}

**INSTRU√á√ïES IMPORTANTES:**
- Seja natural, amig√°vel e profissional
- Use emojis moderadamente
- N√ÉO adicione "oi" ou cumprimentos desnecess√°rios nas respostas
- APENAS cumprimente se for realmente apropriado (primeira mensagem ou resposta a cumprimento)
- Fa√ßa uma pergunta por vez quando precisar de mais informa√ß√µes
- Quando tiver informa√ß√µes suficientes, forne√ßa as sugest√µes completas
- Mantenha respostas concisas mas informativas
- V√° direto ao ponto sem cumprimentos repetitivos`;

    const result = await model.generateContent(prompt);
    const fullText = (await result.response).text();
    // Divide a resposta em bolhas curtas (m√°ximo 2 quebras de linha por bolha)
    const bubbles = fullText
      .split(/\n{2,}/)
      .map(msg => msg.trim())
      .filter(Boolean)
      .map(msg => (msg.length > 180 ? msg.slice(0, 180) + '...' : msg));
    return bubbles;
    
  } catch (error: Error | unknown) {
    console.error('Erro na IA:', error);
    
    // Fallback quando API do Gemini falha (limite de quota ou indisponibilidade)
    const status = (error as { status?: number })?.status;
    if (status === 429 || status === 503) {
      return generateFallbackResponse(message, {
        occasion: profile.ocasiao,
        weather: profile.weatherData?.condition,
        style: profile.estiloDesejado
      }, conversationHistory);
    }
    return "Desculpe, tive um problema t√©cnico. Pode repetir sua mensagem?";
  }
}

// Endpoint POST
export async function POST(request: NextRequest) {
  try {
    const { message, conversationHistory, userProfile } = await request.json();
    
    // Extrai informa√ß√µes da mensagem atual
    const extractedInfo = extractInfoFromMessage(message);
    
    // Atualiza o perfil do usu√°rio com as novas informa√ß√µes
    const updatedProfile = {
      ...userProfile,
      ...extractedInfo
    };
    
    // Chama a IA para gerar a resposta
    const aiResponse = await callGeminiForChat(message, updatedProfile, conversationHistory);
    
    return NextResponse.json({
      messages: Array.isArray(aiResponse) ? aiResponse : [aiResponse],
      userProfile: updatedProfile
    });
    
  } catch (error) {
    console.error('Erro no chat:', error);
    return NextResponse.json(
      { error: 'Erro interno do servidor' },
      { status: 500 }
    );
  }
}